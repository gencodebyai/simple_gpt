Traceback (most recent call last):
  File "/Users/zxw/code/gpt_by_ai/src/train.py", line 58, in <module>
    main() 
  File "/Users/zxw/code/gpt_by_ai/src/train.py", line 27, in main
    model = GPT(config).to(config.device)
  File "/Users/zxw/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/Users/zxw/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/Users/zxw/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/Users/zxw/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/Users/zxw/Library/Python/3.9/lib/python/site-packages/torch/cuda/__init__.py", line 293, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled
